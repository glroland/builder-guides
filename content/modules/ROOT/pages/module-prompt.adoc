= Prompting Basics
:imagesdir: ../assets/images
:sectnums:

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HTRSDJ3M4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HTRSDJ3M4');
</script>
++++

== Goals of this lab

Parasol has had mixed success in the past with generative AI, and believes that better prompts can improve their results. As an AI model builder, it is your job to build in the prompts that will be combined with user input to query the custom Parasol models.

In this exercise you as an AI model builder will delve into the art of crafting effective prompts to improve the performance of Parasol's customized generative AI models. Recognizing the importance of precise and well-structured prompts, this exercise aims to equip you with the best practices to optimize user interactions with custom AI models. You'll start by initiating the "Prompt Best Practices" recipe on Podman Desktop, configured with a tailored model. From there, you'll open the application frontend in your browser and experiment with various prompt types, including zero-shot, few-shot, and chain-of-thought prompts, using examples to showcase the reasoning capabilities of the language model. Additionally, you'll use these prompts to generate emails that meet specific content, formatting, and tone requirements. This hands-on exercise will empower you to refine your prompting techniques, ultimately enhancing the overall effectiveness of Parasol's AI initiatives.

== Run Podman Desktop with AI Lab

=== What is Podman Desktop?

Podman Desktop is an open source tool that enables you to easily work with containerized applications in an easy to use graphical user interface that is local to your machine.  It is built upon an extensible architecture and AI Lab provides tooling for interacting with Large Language Models in an easy to use, local environment.  For this workshop, we will be connect to a remote desktop instantiated for our session today that is preconfigured for Podman Desktop with AI Lab.  This environment is also GPU enabled, helping to support expidited responses to your test queries.

If you would like to install Podman Desktop in your own environment, visit podman-desktop.io and click Download Now!  Once installed, click the download button next to AI Lab on either the home screen or search for it in the Extensions view.

=== Access Virtual Environment

Open the novnc url to connect to the remote desktop.  Enter the password provided to you when prompted.
Next, click on the Podman Desktop icon on your desktop when you login.  (TODO - this needs to happen)  Should this icon not be here, the command to run this application from the terminal is "flatpak run io.podman_desktop.PodmanDesktop".

=== Download the Trained Parasol Insurance LLM

Open the terminal and use wget or curl to download the remote model in GGUF format.  GPT-Generated Unified Format (GGUF) is a file format popularized by Hugging Face designed for fast loading and saving of models.  It is centered on a singular file, simplifying reading and distribution.

Download our specialized GGUF model that has been pretrained for Parasol Insurance specific use cases.

* Open a terminal window using the icon on the desktop and enter the following command:
 - wget https://huggingface.co/rh-rad-ai-roadshow/parasol-merlanite-trained-GGUF/resolve/main/parasol-model-07-24-24-sdg100.gguf
* For this lab, open the permissions so the file can be read by containerized processes:
** chmod 666 parasol-model-07-24-24-sdg100.gguf
- The file will be saved to demo user's home directory.  If you used a different directory to store the model, please note that location.

=== Start Podman Desktop with AI Lab

Start Podman Desktop with AI Lab using the Podman Desktop icon on your desktop.  Alternatively, it can also be started from a terminal using the following command:
* flatpak run io.podman_desktop.PodmanDesktop

You will see a list of icons along the left hand side providing functionality for a variety of features in support of containerized applications.  Containerized AI applications are a popular trend across the industry due to its ease of consistently deploying across ecosystems and runtime platforms. 

=== Open AI Lab and Import the LLM

Open AI Lab using the icon towards the bottom of the bar along the left hand side.  Its the happy robot head!

AI Lab is helpful to model builders because it simplifies direct inquiries into the model and provides GUI based tooling for packaging, should a container be appropriate for their use case.  To begin experimenting with the model, we must first important it using the following steps:

* Click Catalog
* Click the purple Import button on the top right hand side of the screen.
* Click the "Add .GGUF Models" link in the center of the screen.
* Navigate to the home directory and select the model we downloaded above using the wget command.   If you chose a different file location, now would be the time to use that alternative location.  Select that model in the file selection dialog.

== Use Playgrounds to Chat with the Model

=== Create a Playground

Playgrounds is the area of AI Lab where users can experiment with  basic prompting techniques against a particular LLM.  Let's begin by creating a Playground for this workshop.

* Click Playgrounds
* Click the purple "New Playground" button on the top right hand side of the window
* The playground name does not matter for this experiment.  Feel free to enter one or leave blank.
* Select the Parasol Insurance model that was imported in the prior step.  This is likely the only model in your selection and therefore selected by default.
* Click the Create Playground button in the middle of the window.

=== Enter the System Prompt

As we reviewed before, prompting is as important to getting value from a model as training.  Prompting begins with a system prompt, which is where we recommend personas, context and guardrails be established.  The System Prompt is a required field in AI Lab.  Since our initial project for Parasol Insurance is focused on policy rules and regulatory requirements, let's go ahead and set that context here.

* Click the Edit button next to the System Prompt text box.
* Paste the following text into that dialog:
 - You are an insurance expert at Parasol Insurance who specializes in rules and regulations as they relate to insurance policies and coverages.  You are expected to be concise, emphathetic to the user or customer, and answer questions with responses grounded in facts specifically related to Parasol Insurance.  Do not answer questions unrelated to insurance or Parasol Insurance.  
* Click the Check button next to the System Prompt text box.

=== Configure the Playground

Since we are and will be experimenting with various prompts, its best to constrain the amount of tokens expected from the LLM to help avoid unnecessary long running requests. 
* Set the Max Tokens value to 200 by typing this directly into the text box.  It isn't required that this be exactly 200, if you want to use the slider bar instead.

=== Chat with the LLM

Now, let's use a simple prompt that we know uses data that was included in the previous fine tuning exercises.

* Enter the following text into the User Prompt text box at the very bottom of the page.
 - Is rental car coverage included in the most basic vehicle insurance policy?
* Click the purple action button with the arrow icon.  If the arrow button isn't clickable, it likely means that the inference service did not start and that is likely because it cannot find or have access to the model you previously imported.

The response will be negative or a direct No.

=== Propigation of Chat History

Chat platgrounds in AI Lab carry the questions you previously asked with you ask further questions are asked.  This context will help the LLM provide more meaningful responses or continue with implied context for follow on inqueries.  Now ask the following question in the same chat session:
How much does it cost?

The LLM will now respond with what factors influence the cost of adding rental car insurance.  Notice that the system was able to infer the meaning of "it".  Also notice that it didn't provide a specific dollar value as it relates to the customer inquiry.  Numbers, calculations, math and data specific context (like that associated with a specific customer) are specific challenges we will look at later.  For now, we are focusing on more general usage of the LLM.

=== Ignoring Non-Insurance Related Questions

Now, let's see if the LLM is still adhering to our guidance in the system prompt.  Ask it the following question about tennis shoes and confirm that it declines to comment:

* What Nike tennis shoes are most popular with teenagers?

The LLM should decline to answer the question.

=== Have Some Fun!

Take some time to ask the LLM various questions and see how it responds.  Remember, chat history influences the next response so start new playgrounds as needed for a fresh start.

=== Clean Up Playgrounds

Before moving to the next section, let's free up system resources by deleting the playgrounds you previously created.

* Click on Services
* Click the checkbox at the highest point in the services list, which automatically checks everything when selected.
* Click the Delete Items button that now appears and choose ok when prompted for confirmation.
* Click on Playgrounds
* Click the Trash Can icon next to each playground in the list.  Click Confirm when prompted for confirmation.

== Try the Summarization Recipe on an Insurance Claimed

=== Start the Summarization Recipe

* In Podman Desktop, go to AI Lab and click on Recipes Catalog
* Click Summarizer
 - Notice that the Granite foundational model is selected instead of the model previously trained.  For this exercise, that is ok.
* Click Start AI Application and wait for the model to download and the application to start
* Once it starts, an arrow icon will appear.  Click on it to open the application in Firefox.

=== Download a File to Summarize

* Open a tab in the firefox window that was just opened and visit the following URL:
 - https://github.com/rh-rad-ai-roadshow/parasol-insurance/raw/main/app/src/main/resources/claims/marty-mcfly-auto.pdf
* Save the file to the Downloads folder in your home directory.  (default location)

=== Summarize an Insurance Claim PDF

* Return to the summarizer tab in FireFox.
* Click on the Browse Files button.
* Navigate to where the previous PDF was saved.  (Downloads quick visit button on the left)
* Choose the Marty McFly Insurance Claim PDF

The process will take a few moments to complete.  When it does, you will see an accurate translation of the doc using clear, easy to follow bullet points that focus on facts contained in the submitted document.

=== Try Other Documents!

Try downloading and submitting your own documents to experiment with performance.

Keep in mind this is an insecure business server and confidential data should be avoided, along with offensive material.  Also, keep in mind maximum length guidance as provided in the UI.

== Solve a Business Problem with a Prompt!

=== Use Case and Requirements

Customers frequently reach out to our customer service team to discuss their insurance claims.  These emails are very diverse and, while we can easily route them to the claims team, determining how to process from there is time consuming manual labor that Parasol Insurance would like to repurpose elsewhere within the company.  This is where you come in - Parasol Insurance leadership is eager to pilot Generative AI in the context of claims email routing.  It hopes this automation will allow it to move these claims support resources to the claims analysis team, who is getting behind in their processes and causing customer impacting delays.

As the Model Builder, you have already completed training of a robust LLM that is are of Parasol Insurance's business rules.  We will use this model to analyze customer emails and determine how to best handle the customer inquiry.  Architecturally, this logic will be invoked as a simple business service written in Java that generates a simple response that guides routing.  The robust analysis must be performed by the LLM and will require solid prompt to produce quality results.

* Input/Output Specification:
 - LLM Input:  "customer email body"
 - LLM Output: { "claimStatus": "RESPONSE" } where RESPONSE is either NEW, EXISTING, UNRELATED, or UNKNOWN

* Requirements:
 - Determine if the customer email is notifying the company of a new insurance claim or asking about an existing one.
 - If the email was misrouted to the claim team for some reason, respond with UNRELATED
 - Non-business emails should be assigned UNKNOWN

=== Prepare for Prompt Experimentation

* Open Podman Desktop AI Lab
* Click on AI Lab
* Click on Playgrounds
* Click on New Playground
* Choose the Parasol Insurance model 
* Click the Create playbround button
* Set the Max Tokens to a definitive value - something smaller like 100-200 tokens

=== Write a prompt!

Think about what we've learned so far with LLMs and ground yourself in clear communication vs the power of AI.  How would you communicate this use case to a new employee with no background at all in insurance or customer service?  How would you communicate what good looks like in a way that is descriptive of a pattern vs rigid rules that must be followed?

I recommend that you start with a text editor in the shared desktop and then paste updates into Podman Desktop, as this will be an interative process.
A hint - the user prompt will always be the customer email with no other surrounding questions or text.  This means your system prompt will contain all of the instructions for this exercise.  Each change to a system prompt requires a new playground session so pasting this in will help simplify the continuous improvement process.

You can write your own sample emails and paste them into the user prompt text box or you can view them in the Parsol Insurance App.  For the latter, open the web application, click on Claims, select any of the claims in the list and emails are included in the Document tab.

If you run into challenges while drafting the prompt, ask your instructor for assistance.

If you finish this exercise early, can you enhance the process with the following:

* If the response is NEW, is there a customer provided policy number that you can include in the response?  If not, can you return an error message with the code saying that more information is needed?
* If the response is EXISTING, is the claim number provided?  If not, can you return an error message with the EXISTING response?
* Enrich the JSON with the additional data fields.

== Update the Parasol Insurance Java App w/New Prompt

=== Objectives

Now that you've developed a working prompt that can help satisfy leadership objectives with its first Generative AI initiative, you need to incorporate the logic into the Parasol Insurance systems and applications.  For this exercise, that involves updating a REST service that provides routing guidance based on a customer email.  You will update this service to include the prompt and then validate its response.

=== Working Prompt

You are a customer service expert in the claims management processes at Parasol Insurance. 

You are the first point of contact for customer emails involving insurance claims. These emails always fall into one of the following categories - 1.) New Claim , 2.) Status Updates or Additional Details Regarding an Existing Claim, or 3.) Unrelated to Insurance Claims. 

Emails that describe a new accident or discuss filing a new claim are always NEW claims. 
 
Emails that are asking for a status update, voicing concerns about taking too long to process, or providing additional details about an accident that were not previously provided are always EXISTING claims. 

Emails that have nothing to do with insurance or claims are always UNRELATED. 

Any email that cannot be categorized into NEW, EXISTING, or UNRELATED must be categorized as UNKNOWN. 

You will be provided the email body in user prompt and will review it to determine which category to which it belongs. You MUST ALWAYS respond with only one of the following words - NEW, EXISTING, UNRELATED, or UNKNOWN. 

Provide this response in JSON format in the following structure: { "claimStatus": "RESPONSE" } where "RESPONSE" contains NEW, EXISTING, UNRELATED, or UNKNOWN. 

=== Integrate Prompt with Application

TODO


== Conclusion

We hope you have enjoyed this module!

Here is a quick summary of what we have learned:

- Learned how to use Podman Desktop with AI Lab to chat with a trained model
- Explored common use cases for gaining value from an LLM, such as agents, summarization and content analysis
- Developed a new prompt from scratch in support of a new business use case
