= Prompting Basics
:imagesdir: ../assets/images
:sectnums:

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HTRSDJ3M4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HTRSDJ3M4');
</script>
++++

== Goals of this lab

Parasol has had mixed success in the past with generative AI, and believes that better prompts can improve their results. As an AI model builder, it is your job to build in the prompts that will be combined with user input to query the custom Parasol models.

In this exercise you as an AI model builder will delve into the art of crafting effective prompts to improve the performance of Parasol's customized generative AI models. Recognizing the importance of precise and well-structured prompts, this exercise aims to equip you with the best practices to optimize user interactions with custom AI models. You'll start by initiating the "Prompt Best Practices" recipe on Podman Desktop, configured with a tailored model. From there, you'll open the application frontend in your browser and experiment with various prompt types, including zero-shot, few-shot, and chain-of-thought prompts, using examples to showcase the reasoning capabilities of the language model. Additionally, you'll use these prompts to generate emails that meet specific content, formatting, and tone requirements. This hands-on exercise will empower you to refine your prompting techniques, ultimately enhancing the overall effectiveness of Parasol's AI initiatives.

== 1. Run Podman Desktop with AI Lab

=== 1.1. What is Podman Desktop?

Podman Desktop is an open source tool that enables you to easily work with containerized applications in an easy to use graphical user interface that is local to your machine.  It is built upon an extensible architecture and AI Lab provides tooling for interacting with Large Language Models in an easy to use, local environment.  For this workshop, we will be connect to a remote desktop instantiated for our session today that is preconfigured for Podman Desktop with AI Lab.  This environment is also GPU enabled, helping to support expidited responses to your test queries.

If you would like to install Podman Desktop in your own environment, visit podman-desktop.io and click Download Now!  Once installed, click the download button next to AI Lab on either the home screen or search for it in the Extensions view.

=== 1.2. Access Virtual Environment

Open the novnc url to connect to the remote desktop.  Enter the password provided to you when prompted.
Next, click on the Podman Desktop icon on your desktop when you login.  (TODO - this needs to happen)  Should this icon not be here, the command to run this application from the terminal is "flatpak run io.podman_desktop.PodmanDesktop".

=== 1.3. Download the Trained Parasol Insurance LLM to Experiment Against

Open the terminal and use wget or curl to download the remote model in GGUF format.  GPT-Generated Unified Format (GGUF) is a file format popularized by Hugging Face designed for fast loading and saving of models.  It is centered on a singular file, simplifying reading and distribution.

Download our specialized GGUF model that has been pretrained for Parasol Insurance specific use cases.

Open a terminal window using the icon on the desktop and enter the following command:
wget https://huggingface.co/rh-rad-ai-roadshow/parasol-merlanite-trained-GGUF/resolve/main/parasol-model-07-24-24-sdg100.gguf
For this lab, open the permissions so the file can be read by containerized processes:
chmod 666 parasol-model-07-24-24-sdg100.gguf
The file will be saved to demo user's home directory.  If you used a different directory to store the model, please note that location.

=== 1.4. Start Podman Desktop with AI Lab

Start Podman Desktop with AI Lab using the Podman Desktop icon on your desktop.  Alternatively, it can also be started from a terminal using the following command:
flatpak run io.podman_desktop.PodmanDesktop

You will see a list of icons along the left hand side providing functionality for a variety of features in support of containerized applications.  Containerized AI applications are a popular trend across the industry due to its ease of consistently deploying across ecosystems and runtime platforms. 

=== 1.5. Open AI Lab and Import the LLM

Open AI Lab using the icon towards the bottom of the bar along the left hand side.  Its the happy robot head!.

AI Lab is helpful to model builders because it simplifies direct inquiries into the model and provides GUI based tooling for packaging, should a container be appropriate for their use case.  To begin experimenting with the model, we must first important it using the following steps:

Click Catalog
Click the purple Import button on the top right hand side of the screen.
Click the "Add .GGUF Models" link in the center of the screen.
Navigate to the home directory and select the model we downloaded above using the wget command.   If you chose a different file location, now would be the time to use that alternative location.  Select that model in the file selection dialog.

== 2. Use Playgrounds to Chat with the Model

=== 2.1. Create a Playground

Playgrounds is the area of AI Lab where users can experiment with  basic prompting techniques against a particular LLM.  Let's begin by creating a Playground for this workshop.
Click Playgrounds
Click the purple "New Playground" button on the top right hand side of the window
The playground name does not matter for this experiment.  Feel free to enter one or leave blank.
Select the Parasol Insurance model that was imported in the prior step.  This is likely the only model in your selection and therefore selected by default.
Click the Create Playground button in the middle of the window.

=== 2.2. Enter the System Prompt

As we reviewed before, prompting is as important to getting value from a model as training.  Prompting begins with a system prompt, which is where we recommend personas, context and guardrails be established.  The System Prompt is a required field in AI Lab.  Since our initial project for Parasol Insurance is focused on policy rules and regulatory requirements, let's go ahead and set that context here.

Click the Edit button next to the System Prompt text box.
Paste the following text into that dialog:
You are an insurance expert at Parasol Insurance who specializes in rules and regulations as they relate to insurance policies and coverages.  You are expected to be concise, emphathetic to the user or customer, and answer questions with responses grounded in facts specifically related to Parasol Insurance.  Do not answer questions unrelated to insurance or Parasol Insurance.  
Click the Check button next to the System Prompt text box.

=== 2.3. Configure the Playground

Since we are and will be experimenting with various prompts, its best to constrain the amount of tokens expected from the LLM to help avoid unnecessary long running requests. 
Set the Max Tokens value to 200 by typing this directly into the text box.  It isn't required that this be exactly 200, if you want to use the slider bar instead.

=== 2.4. Chat with the LLM

Now, let's use a simple prompt that we know uses data that was included in the previous fine tuning exercises.
Enter the following text into the User Prompt text box at the very bottom of the page.
Is rental car coverage included in the most basic vehicle insurance policy?
Click the purple action button with the arrow icon.  If the arrow button isn't clickable, it likely means that the inference service did not start and that is likely because it cannot find or have access to the model you previously imported.
The response will be negative or a direct No.

=== 2.5 Propigation of Chat History

Chat platgrounds in AI Lab carry the questions you previously asked with you ask further questions are asked.  This context will help the LLM provide more meaningful responses or continue with implied context for follow on inqueries.  Now ask the following question in the same chat session:
How much does it cost?

The LLM will now respond with what factors influence the cost of adding rental car insurance.  Notice that the system was able to infer the meaning of "it".  Also notice that it didn't provide a specific dollar value as it relates to the customer inquiry.  Numbers, calculations, math and data specific context (like that associated with a specific customer) are specific challenges we will look at later.  For now, we are focusing on more general usage of the LLM.

=== 2.6 Ignoring Non-Insurance Related Questions

Now, let's see if the LLM is still adhering to our guidance in the system prompt.  Ask it the following question about tennis shoes and confirm that it declines to comment:
What Nike tennis shoes are most popular with teenagers?

=== 2.7 Have Some Fun!

Take some time to ask the LLM various questions and see how it responds.  Remember, chat history influences the next response so start new playgrounds as needed for a fresh start.

=== 2.8 Clean Up Playgrounds

Before moving to the next section, let's free up system resources by deleting the playgrounds you previously created.
Click on Services
Click the checkbox at the highest point in the services list, which automatically checks everything when selected.
Click the Delete Items button that now appears and choose ok when prompted for confirmation.
Click on Playgrounds
Click the Trash Can icon next to each playground in the list.  Click Confirm when prompted for confirmation.

== 3. Try the Summarization Recipe on an Insurance Claimed

=== 3.1. Start the Summarization Recipe

In Podman Desktop, go to AI Lab and click on Recipes Catalog
Click Summarizer
Notice that the Granite foundational model is selected instead of the model previously trained.  For this exercise, that is ok.
Click Start AI Application and wait for the model to download and the application to start
Once it starts, an arrow icon will appear.  Click on it to open the application in Firefox.

=== 3.2. Download a File to Summarize

Open a tab in the firefox window that was just opened and visit the following URL:
https://github.com/rh-rad-ai-roadshow/parasol-insurance/raw/main/app/src/main/resources/claims/marty-mcfly-auto.pdf
Save the file to the Downloads folder in your home directory.  (default location)

=== 3.3. Summarize an Insurance Claim PDF

Return to the summarizer tab in firefix.
Click on the Browse Files button.
Navigate to where the previous PDF was saved.  (Downloads quick visit button on the left)
Choose the Marty McFly Insurance Claim PDF

The process will take a few moments to complete.  When it does, you will see an accurate translation of the doc using clear, easy to follow bullet points that focus on facts contained in the submitted document.

=== 3.4. Try Other Documents!

Try downloading and submitting your own documents to experiment with performance.

Keep in mind this is an insecure business server and confidential data should be avoided, along with offensive material.  Also, keep in mind maximum length guidance as provided in the UI.

== 4. Write a Use Case Prompt for Later Use with an Insurance Business Service



== 5. Update the Parasol Insurance Java App w/New Prompt



== Conclusion

We hope you have enjoyed this module!

Here is a quick summary of what we have learned:

- TBD
- TBD
- TBD