= Model Fine-tuning with InstructLab
:imagesdir: ../assets/images
:sectnums:

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HTRSDJ3M4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HTRSDJ3M4');
</script>
++++

== The AI Model Journey for Parasol Insurance

As Parasol Insurance embraces the era of AI, we face a unique challenge: leveraging cutting-edge AI technology while maintaining strict control over our proprietary data and processes. This journey requires us to develop in-house AI capabilities that are as powerful as they are secure.

Our path forward involves three critical steps:

. Knowledge Infusion
* How do we incorporate Parasol's unique insurance expertise into AI models?
. Model Customization
* How can we fine-tune AI to address Parasol-specific scenarios and regulations?
. Secure Deployment
* What's the best way to integrate AI into our workflow while keeping data in-house?

// image::instructlab/parasol-ai-journey.png[Parasol's Private AI Journey]

== Goals of this lab

In this hands-on session, you'll dive into the world of private AI development for Parasol Insurance. By the end of this lab, you will:

* *Understand* the fundamentals of InstructLab and its role in creating customized, private AI models.
* *Create* a Parasol-specific knowledge base by modifying the InstructLab taxonomy.
* *Generate* synthetic training data that reflects Parasol's unique insurance scenarios.
* *Train* a Large Language Model (LLM) with Parasol's proprietary information.
* *Interact* with the newly trained model to verify its insurance-specific capabilities.
* *Deploy* the customized model locally before moving to production with Parasol's secure infrastructure on OpenShift AI.

This lab will equip you to enhance Parasol's AI capabilities in three key areas:

1. Generating product-specific email templates
2. Providing comprehensive policy and product information
3. Offering insights on relevant local regulations

By mastering these skills, you'll be at the forefront of Parasol's AI innovation, enabling more efficient, accurate, and compliant customer service.

== Get Started with InstructLab

=== What is InstructLab?

https://instructlab.ai/[InstructLab] is an open-source project designed to enhance large language models (LLMs) for use in generative AI applications. It provides a novel approach to model alignment and fine-tuning, allowing developers and domain experts to add new knowledge and skills to pre-trained models with minimal data and computational resources. Key features of InstructLab include:

* A taxonomy-driven approach to curating training data
* Large-scale synthetic data generation
* Iterative, large-scale alignment tuning

InstructLab is particularly useful for organizations like Parasol that want to leverage private AI and keep their data in-house while still benefiting from state-of-the-art language models.

=== Access your Virtual Environment

To begin working with InstructLab, you'll need to access the provided noNVC virtual environment. This environment comes pre-configured with all necessary tools and dependencies: {novnc_url}[*{novnc_url}*,window=_blank], using the password `{password}`.

. Click the `Activities` label in the top-left corner of the screen.
. Click the `Show Applications` icon to show all the applications.
. Click the `Visual Studio Code` icon to launch Visual Studio Code.

image::ilab/launch-vscode-desktop.png[Launch Podman Desktop]

[start=4]
. From the `Terminal` menu, select `New Terminal` to open a new terminal window.

image::ilab/vscode-new-terminal-menu.png[Open new VSCode terminal]

== Hands on with AI Model Fine-tuning

In this section, we'll walk through the process of fine-tuning an AI model using InstructLab. We'll start by setting up our environment, generating synthetic training data, training the model, and then interact with it.

=== Initializing InstructLab

Before we can start fine-tuning our model, we need to initialize InstructLab in our working environment. This process sets up the necessary configuration and downloads the required taxonomy for us to work with.

. In your terminal, ensure you're in the InstructLab directory:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
mkdir instructlab && cd instructlab
----

. Activate your Python virtual environment:
[.console-input]
[source,bash,subs="+attributes,macros+"]
----
source venv/bin/activate
----

. Now, you should see the virtual environment name `(venv)` in your terminal prompt, indicating that the virtual environment is active:

[.console-output]
[source,adoc]
----
[student@rhel9 ~]$ mkdir instructlab && cd instructlab
[student@rhel9 instructlab]$ source venv/bin/activate
(venv) [student@rhel9 instructlab]$ 
----

. Now, initialize InstructLab by running the following command:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab config init
----

. When prompted, press Enter to use the default `config.yaml` file location.

. When asked if you want to clone the taxonomy repository, type `y` and press Enter.

You should see output similar to this:

[.console-output]
[source,adoc]
----
Welcome to InstructLab CLI. This guide will help you to setup your environment.
Please provide the following values to initiate the environment [press Enter for defaults]:
Path to taxonomy repo [taxonomy]: 
`taxonomy` seems to not exist or is empty. Should I clone https://github.com/instructlab/taxonomy.git for you? [y/N]: y
Cloning https://github.com/instructlab/taxonomy.git...
Generating `config.yaml` in the current directory...
Initialization completed successfully, you're ready to start using `ilab`. Enjoy!
(venv) [student@rhel9 instructlab]$
----

=== Downloading the Base Model

Before we can fine-tune the model, we need to download the base model that we'll be working with.

. Download the model using the following command:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab model download
----

This command will download a compact pre-trained version of the model (~4.4GB) from HuggingFace and store it in a `models` directory (the process may take a minute or two). You should see output indicating the download progress and completion:

[.console-output]
[source,adoc]
----
Downloading model from instructlab/merlinite-7b-lab-GGUF@main to models...
----

=== Adding training data to the Taxonomy

The InstructLab taxonomy is a structured knowledge base that guides the model fine-tuning process. By customizing the taxonomy, we can add domain-specific knowledge to the model.

. Open the `instructlab` directory in Visual Studio Code through the terminal:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
code -r .
----

. Navigate and create a `taxonomy/knowledge/parasol/qna.yaml` file in the editor. This file will contain the questions and answers that will be used to train the model.
. Add the following question and answer pair to the `qna.yaml` file:

[source,yaml]
----
blabla
----

This is a simple example of a question and answer pair that will be used to train the model, through the synthetic data generation process performed later.

=== Generating Synthetic Training Data

// Make sure to add serving instructions for the model in this step

Now that we've added some initial data, let's use InstructLab to generate synthetic training data.

. Open a terminal in Visual Studio Code.
. Run the following command to generate synthetic training data:
+
[source,bash]
----
cd ~/instructlab
----
. Activate the Python virtual environment:
+
[source,bash]
----
source venv/bin/activate
----
. Run the data generation command:
+
[source,bash]
----
ilab data generate
----

This process may take some time, depending on the amount of data and the computational resources available. The synthetic data will be created in the `generated` directory.

=== Training the Model with New Data

With our synthetic data generated, we can now train the model to incorporate this new knowledge.

. In the terminal, ensure you're still in the InstructLab directory and the virtual environment is activated.
. Run the training command:
+
[source,bash]
----
ilab model train
----

This process will take some time, potentially several hours depending on your hardware. The command will output progress information as it trains the model.

=== Interacting with the Model

Once training is complete, we can interact with the newly fine-tuned model to test its capabilities.

. In the terminal, start the model server:
+
[source,bash]
----
ilab model serve --model-path models/ggml-model-f16.gguf
----
. Open a new terminal window, navigate to the InstructLab directory, and activate the virtual environment.
. Start a chat session with the model:
+
[source,bash]
----
ilab model chat
----
. Test the model with questions related to the knowledge we added, for example:
+
[source]
----
What types of insurance does Parasol offer?
----
+
[source]
----
Can you explain Parasol's process for handling auto insurance claims?
----

Observe how the model incorporates the new knowledge into its responses.

// == Integrating the Model in the Application Development Workflow

// === Loading the Model in Podman AI Lab

// Now that we have a fine-tuned model, we can integrate it into our development workflow using Podman Desktop's AI Lab

// . Open Podman Desktop from your virtual environment.
// . On the left-hand menu, click on "AI Lab" icon to access the AI Lab environment.
// . Click on "Models" to view the available models.
// . Click on "Import Model" and select the model file we trained earlier.
// . Once the model is imported, you can start it as a service and integrate it in your applications.


// Table of Contents

// 1. Get Started with InstructLab [Cedric/Shaaf]
// 1.1. What is InstructLab [Cedric/Shaaf]
// 1.2. Access Virtual Environment [Cedric/Shaaf]
// 2. Hands on with AI Model Fine-tuning [Cedric]
// 2.1. Starting from Example Data in VSCode (ex. 5 instructions) [Cedric]
// 2.2. Generating Synthetic Training Data [Cedric]
// 2.3. Training the Model with New Data [Cedric]
// 2.4. Interacting with the Model [Cedric]
// 3. Model Training for the Insurance Organization [Shaaf]
// 3.1. Viewing the Synthetic Data Generated [Shaaf]
// 3.2. Training the Model (15 mins) [Shaaf]
// 3.3. Interacting with the Model [Shaaf]
// 4. Integrating the Model in the Application Development Workflow [Cedric]
// 4.1 Loading the Model in Podman Desktop [Cedric]
// 4.2 Sharing the Model beyond the local environment [Shaaf]